{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "\n",
    "for i in range(40669):\n",
    "    img = cv2.imread('../DB/test-jpg/test_{}.jpg'.format(i))\n",
    "    x_test.append(cv2.resize(img, (64, 64)))\n",
    "    \n",
    "    \n",
    "for i in range(20522):\n",
    "    img = cv2.imread('../DB/test-jpg-additional/file_{}.jpg'.format(i))\n",
    "    x_test.append(cv2.resize(img, (64, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{14: 'agriculture', 5: 'artisinal_mine', 1: 'bare_ground', 3: 'blooming', 0: 'blow_down', 10: 'clear', 16: 'cloudy', 2: 'conventional_mine', 4: 'cultivation', 9: 'habitation', 6: 'haze', 13: 'partly_cloudy', 7: 'primary', 11: 'road', 12: 'selective_logging', 8: 'slash_burn', 15: 'water'}\n"
     ]
    }
   ],
   "source": [
    "label_map = {'agriculture': 14,\n",
    " 'artisinal_mine': 5,\n",
    " 'bare_ground': 1,\n",
    " 'blooming': 3,\n",
    " 'blow_down': 0,\n",
    " 'clear': 10,\n",
    " 'cloudy': 16,\n",
    " 'conventional_mine': 2,\n",
    " 'cultivation': 4,\n",
    " 'habitation': 9,\n",
    " 'haze': 6,\n",
    " 'partly_cloudy': 13,\n",
    " 'primary': 7,\n",
    " 'road': 11,\n",
    " 'selective_logging': 12,\n",
    " 'slash_burn': 8,\n",
    " 'water': 15}\n",
    "\n",
    "inv_label_map = {value: key for key, value in label_map.items()}\n",
    "print(inv_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[66 73 62]\n",
      "  [67 74 67]\n",
      "  [69 77 70]\n",
      "  ..., \n",
      "  [81 94 88]\n",
      "  [80 97 91]\n",
      "  [73 78 70]]\n",
      "\n",
      " [[69 76 64]\n",
      "  [70 77 68]\n",
      "  [71 81 73]\n",
      "  ..., \n",
      "  [77 88 80]\n",
      "  [78 89 81]\n",
      "  [73 80 72]]\n",
      "\n",
      " [[71 77 69]\n",
      "  [69 79 69]\n",
      "  [70 81 70]\n",
      "  ..., \n",
      "  [73 82 70]\n",
      "  [74 82 75]\n",
      "  [74 85 76]]\n",
      "\n",
      " ..., \n",
      " [[71 81 72]\n",
      "  [69 75 65]\n",
      "  [69 81 69]\n",
      "  ..., \n",
      "  [72 81 70]\n",
      "  [73 80 70]\n",
      "  [75 83 74]]\n",
      "\n",
      " [[73 79 72]\n",
      "  [66 75 67]\n",
      "  [66 77 67]\n",
      "  ..., \n",
      "  [71 80 69]\n",
      "  [72 82 71]\n",
      "  [73 85 77]]\n",
      "\n",
      " [[67 76 66]\n",
      "  [70 78 71]\n",
      "  [69 82 69]\n",
      "  ..., \n",
      "  [71 78 70]\n",
      "  [73 82 75]\n",
      "  [75 84 78]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "got 0.6 because I forgot to normalize x_test... :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test  = np.array(x_test, np.float32)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(64, 64,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.load_weights('weights_kfold_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_predictions(predictions, labels_map, thresholds):\n",
    "    \"\"\"\n",
    "    Return the predictions mapped to their labels\n",
    "    :param predictions: the predictions from the predict() method\n",
    "    :param labels_map: the map\n",
    "    :param thresholds: The threshold of each class to be considered as existing or not existing\n",
    "    :return: the predictions list mapped to their labels\n",
    "    \"\"\"\n",
    "    predictions_labels = []\n",
    "    for prediction in predictions:\n",
    "        labels = [labels_map[i] for i, value in enumerate(prediction) if value > thresholds[i]]\n",
    "        predictions_labels.append(labels)\n",
    "\n",
    "    return predictions_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191,)\n"
     ]
    }
   ],
   "source": [
    "thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\n",
    "predicted_labels = map_predictions(predictions, inv_label_map, thres)\n",
    "\n",
    "x_test_filename = ['test_{}.jpg'.format(i) for i in range(40669)]\n",
    "x_test_filename2 = ['file_{}.jpg'.format(i) for i in range(20522)]\n",
    "x_test_filename = np.hstack((x_test_filename, x_test_filename2))\n",
    "print(x_test_filename.shape)\n",
    "\n",
    "tags_list = [None] * len(predicted_labels)\n",
    "for i, tags in enumerate(predicted_labels):\n",
    "    tags_list[i] = ' '.join(map(str, tags))\n",
    "\n",
    "final_data = [[filename.split(\".\")[0], tags] for filename, tags in zip(x_test_filename, tags_list)]\n",
    "\n",
    "final_df = pd.DataFrame(final_data, columns=['image_name', 'tags'])\n",
    "final_df.head()\n",
    "\n",
    "final_df.to_csv('kele_xu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
