{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [10:53<00:00, 61.90it/s]\n",
      "  0%|          | 0/61191 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-70fff169ed7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../ekami/input/test-jpg/{}.jpg'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/imgwarp.cpp:3492: error: (-215) ssize.width > 0 && ssize.height > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('../ekami/input/train_v2.csv')\n",
    "df_test = pd.read_csv('../ekami/input/sample_submission_v2.csv')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'cultivation',\n",
    " 'artisinal_mine',\n",
    " 'haze',\n",
    " 'primary',\n",
    " 'slash_burn',\n",
    " 'habitation',\n",
    " 'clear',\n",
    " 'road',\n",
    " 'selective_logging',\n",
    " 'partly_cloudy',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'cloudy']\n",
    "\n",
    "label_map = {'agriculture': 14,\n",
    " 'artisinal_mine': 5,\n",
    " 'bare_ground': 1,\n",
    " 'blooming': 3,\n",
    " 'blow_down': 0,\n",
    " 'clear': 10,\n",
    " 'cloudy': 16,\n",
    " 'conventional_mine': 2,\n",
    " 'cultivation': 4,\n",
    " 'habitation': 9,\n",
    " 'haze': 6,\n",
    " 'partly_cloudy': 13,\n",
    " 'primary': 7,\n",
    " 'road': 11,\n",
    " 'selective_logging': 12,\n",
    " 'slash_burn': 8,\n",
    " 'water': 15}\n",
    "\n",
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread('../ekami/input/train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (64, 64)))\n",
    "    y_train.append(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 3)\n",
      "(40479, 17)\n",
      "Start KFold number 1 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/20\n",
      "1391s - loss: 0.2695 - acc: 0.9055 - val_loss: 0.2560 - val_acc: 0.9067\n",
      "Epoch 2/20\n",
      "1422s - loss: 0.1596 - acc: 0.9369 - val_loss: 0.1987 - val_acc: 0.9174\n",
      "Epoch 3/20\n",
      "1347s - loss: 0.1490 - acc: 0.9408 - val_loss: 0.1478 - val_acc: 0.9392\n",
      "Epoch 4/20\n",
      "1330s - loss: 0.1422 - acc: 0.9436 - val_loss: 0.1425 - val_acc: 0.9416\n",
      "Epoch 5/20\n",
      "1326s - loss: 0.1368 - acc: 0.9458 - val_loss: 0.1372 - val_acc: 0.9438\n",
      "Epoch 6/20\n",
      "1329s - loss: 0.1330 - acc: 0.9475 - val_loss: 0.1397 - val_acc: 0.9452\n",
      "Epoch 7/20\n",
      "1554s - loss: 0.1287 - acc: 0.9496 - val_loss: 0.1272 - val_acc: 0.9500\n",
      "Epoch 8/20\n",
      "1417s - loss: 0.1257 - acc: 0.9504 - val_loss: 0.1291 - val_acc: 0.9490\n",
      "Epoch 9/20\n",
      "1496s - loss: 0.1234 - acc: 0.9517 - val_loss: 0.1275 - val_acc: 0.9489\n",
      "Epoch 10/20\n",
      "1356s - loss: 0.1218 - acc: 0.9529 - val_loss: 0.1212 - val_acc: 0.9524\n",
      "Epoch 11/20\n",
      "1474s - loss: 0.1185 - acc: 0.9539 - val_loss: 0.1208 - val_acc: 0.9525\n",
      "Epoch 12/20\n",
      "1459s - loss: 0.1162 - acc: 0.9551 - val_loss: 0.1195 - val_acc: 0.9533\n",
      "Epoch 13/20\n",
      "1391s - loss: 0.1160 - acc: 0.9549 - val_loss: 0.1162 - val_acc: 0.9550\n",
      "Epoch 14/20\n",
      "1373s - loss: 0.1136 - acc: 0.9558 - val_loss: 0.1163 - val_acc: 0.9549\n",
      "Epoch 15/20\n",
      "1342s - loss: 0.1114 - acc: 0.9566 - val_loss: 0.1186 - val_acc: 0.9540\n",
      "Epoch 16/20\n",
      "1682s - loss: 0.1124 - acc: 0.9567 - val_loss: 0.1139 - val_acc: 0.9564\n",
      "Epoch 17/20\n",
      "1326s - loss: 0.1102 - acc: 0.9570 - val_loss: 0.1179 - val_acc: 0.9552\n",
      "Epoch 18/20\n",
      "1849s - loss: 0.1085 - acc: 0.9577 - val_loss: 0.1116 - val_acc: 0.9569\n",
      "Epoch 19/20\n",
      "1334s - loss: 0.1081 - acc: 0.9583 - val_loss: 0.1120 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      "1340s - loss: 0.1066 - acc: 0.9587 - val_loss: 0.1126 - val_acc: 0.9571\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      "1406s - loss: 0.0983 - acc: 0.9618 - val_loss: 0.1068 - val_acc: 0.9590\n",
      "Epoch 2/5\n",
      "1407s - loss: 0.0960 - acc: 0.9628 - val_loss: 0.1047 - val_acc: 0.9597\n",
      "Epoch 3/5\n",
      "1375s - loss: 0.0950 - acc: 0.9632 - val_loss: 0.1055 - val_acc: 0.9592\n",
      "Epoch 4/5\n",
      "1559s - loss: 0.0938 - acc: 0.9635 - val_loss: 0.1049 - val_acc: 0.9599\n",
      "Epoch 5/5\n",
      "1477s - loss: 0.0935 - acc: 0.9636 - val_loss: 0.1051 - val_acc: 0.9600\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/5\n",
      "1487s - loss: 0.0927 - acc: 0.9640 - val_loss: 0.1048 - val_acc: 0.9599\n",
      "Epoch 2/5\n",
      "1356s - loss: 0.0922 - acc: 0.9641 - val_loss: 0.1047 - val_acc: 0.9599\n",
      "Epoch 3/5\n",
      "1435s - loss: 0.0916 - acc: 0.9642 - val_loss: 0.1046 - val_acc: 0.9600\n",
      "Epoch 4/5\n",
      "1488s - loss: 0.0916 - acc: 0.9641 - val_loss: 0.1046 - val_acc: 0.9600\n",
      "Epoch 5/5\n",
      "1462s - loss: 0.0918 - acc: 0.9642 - val_loss: 0.1047 - val_acc: 0.9600\n",
      "0.909184402477\n",
      "Start KFold number 2 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f60f4d2af816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n\u001b[0;32m---> 85\u001b[0;31m                   batch_size=128,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/theano/ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "\n",
    "for i in range(40669):\n",
    "    img = cv2.imread('../DB/test-jpg/test_{}.jpg'.format(i))\n",
    "    x_test.append(cv2.resize(img, (64, 64)))\n",
    "    \n",
    "    \n",
    "for i in range(20522):\n",
    "    img = cv2.imread('../DB/test-jpg-additional/file_{}.jpg'.format(i))\n",
    "    x_test.append(cv2.resize(img, (64, 64)))\n",
    "    \n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32)/255.\n",
    "x_test  = np.array(x_test, np.float32)/255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "nfolds = 5\n",
    "\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "\n",
    "yfull_test = []\n",
    "yfull_train =[]\n",
    "\n",
    "kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "        start_time_model_fitting = time.time()\n",
    "        \n",
    "        X_train = x_train[train_index]\n",
    "        Y_train = y_train[train_index]\n",
    "        X_valid = x_train[test_index]\n",
    "        Y_valid = y_train[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "        \n",
    "        kfold_weights_path = os.path.join('', 'weights_kfold_' + str(num_fold) + '.h5')\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(BatchNormalization(input_shape=(64, 64,3)))\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "        epochs_arr = [20, 5, 5]\n",
    "        learn_rates = [0.001, 0.0001, 0.00001]\n",
    "\n",
    "        for learn_rate, epochs in zip(learn_rates, epochs_arr):\n",
    "            opt  = optimizers.Adam(lr=learn_rate)\n",
    "            model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "\n",
    "            model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size=128,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n",
    "        \n",
    "        if os.path.isfile(kfold_weights_path):\n",
    "            model.load_weights(kfold_weights_path)\n",
    "        \n",
    "        p_valid = model.predict(X_valid, batch_size = 128, verbose=2)\n",
    "        print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n",
    "\n",
    "        p_train = model.predict(x_train, batch_size =128, verbose=2)\n",
    "        yfull_train.append(p_train)\n",
    "        \n",
    "        p_test = model.predict(x_test, batch_size = 128, verbose=2)\n",
    "        yfull_test.append(p_test)\n",
    "\n",
    "result = np.array(yfull_test[0])\n",
    "for i in range(1, nfolds):\n",
    "    result += np.array(yfull_test[i])\n",
    "result /= nfolds\n",
    "result = pd.DataFrame(result, columns = labels)\n",
    "result\n",
    "\n",
    "from tqdm import tqdm\n",
    "thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\n",
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.ix[[i]]\n",
    "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))\n",
    "    \n",
    "df_test['tags'] = preds\n",
    "df_test.to_csv('submission_keras_5_fold_CV_0.9136_LB_0.913.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
