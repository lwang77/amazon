{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import scipy as scipy\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import dill\n",
    "\n",
    "import keras as k\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "with open('tiffs.pkl', 'rb') as in_strm:\n",
    "    all_info = dill.load(in_strm)\n",
    "x_train = all_info[0]\n",
    "x_test = all_info[1]\n",
    "y_train = all_info[2]\n",
    "y_test = all_info[3]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "red_dct = scipy.fftpack.dct(x_train[:,:,:,0].astype(np.float64), axis=0)\n",
    "green_dct = scipy.fftpack.dct(x_train[:,:,:,1].astype(np.float64), axis=0)\n",
    "blue_dct = scipy.fftpack.dct(x_train[:,:,:,2].astype(np.float64), axis=0)\n",
    "nir_dct = scipy.fftpack.dct(x_train[:,:,:,3].astype(np.float64), axis=0)\n",
    "train_dct = np.array([red_dct, green_dct, blue_dct, nir_dct])\n",
    "train_dct = train_dct.reshape((train_dct.shape[1], train_dct.shape[2], \n",
    "                               train_dct.shape[3], train_dct.shape[0]))\n",
    "print(train_dct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "red_dct = scipy.fftpack.dct(x_test[:,:,:,0].astype(np.float64), axis=0)\n",
    "green_dct = scipy.fftpack.dct(x_test[:,:,:,1].astype(np.float64), axis=0)\n",
    "blue_dct = scipy.fftpack.dct(x_test[:,:,:,2].astype(np.float64), axis=0)\n",
    "nir_dct = scipy.fftpack.dct(x_test[:,:,:,3].astype(np.float64), axis=0)\n",
    "test_dct = np.array([red_dct, green_dct, blue_dct, nir_dct])\n",
    "test_dct = test_dct.reshape((test_dct.shape[1], test_dct.shape[2], \n",
    "                               test_dct.shape[3], test_dct.shape[0]))\n",
    "print(test_dct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "full_data_train = np.vstack((x_train, train_dct))\n",
    "print(full_data_train.shape)\n",
    "\n",
    "mean = np.mean(full_data_train, axis = 0)\n",
    "x_train -= mean\n",
    "train_dct -= mean\n",
    "std = np.std(full_data_train, axis = 0)\n",
    "x_train /= std\n",
    "train_dct /= std\n",
    "\n",
    "x_test -= mean\n",
    "x_test /= std\n",
    "\n",
    "#don't forget the rest later too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features for x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[ 0.07742251  0.10007736 -0.1009452  ...,  0.06461939 -0.03712822\n",
      "   0.09199761]\n",
      " [-0.00157036  0.13964671 -0.02464548 ..., -0.02835925 -0.09001972\n",
      "   0.12961993]\n",
      " [ 0.12928566 -0.09925903  0.13807824 ..., -0.11269906 -0.13332392\n",
      "   0.07795288]\n",
      " ..., \n",
      " [ 0.14794046 -0.0615038   0.00622906 ...,  0.12479991  0.12324953\n",
      "  -0.04725299]\n",
      " [ 0.11410967  0.11726999 -0.04934318 ...,  0.03382462 -0.03105235\n",
      "  -0.02750045]\n",
      " [ 0.0738124  -0.00937587  0.02215715 ..., -0.11537861  0.09304836\n",
      "   0.04384343]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Epoch 1/2\n",
      "35000/35000 [==============================] - 267s - loss: 0.2844 - acc: 0.8937   \n",
      "Epoch 2/2\n",
      "35000/35000 [==============================] - 257s - loss: 0.2406 - acc: 0.9073   \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1a620418a240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m intermediate_layer_model = Model(inputs=model.input,\n\u001b[1;32m     51\u001b[0m                                  outputs=model.get_layer('test').output)\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermediate_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_means\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_means' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#baseline part\n",
    "original_input = Input(shape=(32, 32, 4))\n",
    "conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(original_input)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(conv1)\n",
    "max1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "drop1 = Dropout(0.25)(max1)\n",
    "flat1 = Flatten()(drop1)\n",
    "dense1 = Dense(128, activation='relu')(flat1)\n",
    "drop2 = Dropout(0.5)(dense1)\n",
    "\n",
    "#mean\n",
    "dct_input = Input(shape=(32, 32, 4))\n",
    "conv3 = Conv2D(32, kernel_size=(3, 3), activation='relu')(dct_input)\n",
    "drop3 = Dropout(0.25)(conv3)\n",
    "flat2 = Flatten()(drop3)\n",
    "dense5 = Dense(128, activation='relu')(flat2)\n",
    "drop4 = Dropout(0.5)(dense5)\n",
    "\n",
    "\n",
    "combine = concatenate([drop2, drop4])\n",
    "dense3 = Dense(256, activation='relu')(combine)\n",
    "dense4 = Dense(17, activation='sigmoid', name='test')(dense3)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[original_input, dct_input], outputs=dense4)\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "weights = model.get_layer('test').get_weights()\n",
    "print(len(weights))\n",
    "print(weights[0])\n",
    "print(weights[1])\n",
    "\n",
    "\n",
    "\n",
    "model.fit([x_train, train_dct],\n",
    "          y_train, batch_size=128, epochs=2, verbose=1)\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer('test').output)\n",
    "intermediate_output = intermediate_layer_model.predict([x_train, train_means])\n",
    "print(intermediate_output[0])\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "p_valid = model.predict(x_test, batch_size=128)\n",
    "print(y_test)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_test, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
