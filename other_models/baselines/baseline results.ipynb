{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import scipy as scipy\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import dill\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "with open('tiffs.pkl', 'rb') as in_strm:\n",
    "    all_info = dill.load(in_strm)\n",
    "x_train = all_info[0]\n",
    "x_test = all_info[1]\n",
    "y_train = all_info[2]\n",
    "y_test = all_info[3]\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5479 samples\n",
      "Epoch 1/7\n",
      "35000/35000 [==============================] - 205s - loss: 0.3446 - acc: 0.8865 - val_loss: 0.2412 - val_acc: 0.9078\n",
      "Epoch 2/7\n",
      "35000/35000 [==============================] - 203s - loss: 0.2457 - acc: 0.9051 - val_loss: 0.2211 - val_acc: 0.9082\n",
      "Epoch 3/7\n",
      "35000/35000 [==============================] - 251s - loss: 0.2339 - acc: 0.9069 - val_loss: 0.2189 - val_acc: 0.9081\n",
      "Epoch 4/7\n",
      "35000/35000 [==============================] - 234s - loss: 0.2264 - acc: 0.9081 - val_loss: 0.2174 - val_acc: 0.9092\n",
      "Epoch 5/7\n",
      "35000/35000 [==============================] - 221s - loss: 0.2216 - acc: 0.9089 - val_loss: 0.2132 - val_acc: 0.9119\n",
      "Epoch 6/7\n",
      "35000/35000 [==============================] - 220s - loss: 0.2195 - acc: 0.9096 - val_loss: 0.2091 - val_acc: 0.9116\n",
      "Epoch 7/7\n",
      "35000/35000 [==============================] - 249s - loss: 0.2165 - acc: 0.9106 - val_loss: 0.2047 - val_acc: 0.9143\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[[  1.29855886e-01   1.17716612e-02   2.35697493e-01 ...,   3.24164331e-02\n",
      "    2.37268001e-01   2.65532676e-02]\n",
      " [  2.15641454e-01   2.10528392e-02   2.86615252e-01 ...,   1.31932637e-02\n",
      "    3.53165954e-01   6.00309819e-02]\n",
      " [  1.55378774e-01   1.48266125e-02   3.00164670e-01 ...,   7.13615073e-03\n",
      "    3.79769683e-01   3.76519263e-02]\n",
      " ..., \n",
      " [  1.98734969e-01   7.76765170e-03   2.73608357e-01 ...,   8.60131186e-05\n",
      "    3.87037069e-01   5.57518080e-02]\n",
      " [  1.73037678e-01   5.71488775e-03   2.81196952e-01 ...,   6.96374918e-05\n",
      "    3.53839427e-01   5.72183803e-02]\n",
      " [  1.45972744e-01   8.79314542e-03   2.65467525e-01 ...,   8.22695345e-03\n",
      "    3.01738441e-01   2.32489295e-02]]\n",
      "0.798873363049\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                input_shape=(32, 32, 4)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=7, verbose=1, \n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "p_valid = model.predict(x_test, batch_size=128)\n",
    "print(y_test)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_test, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inv_label_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3720b5b516db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minv_label_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inv_label_map' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "for i in inv_label_map.keys():\n",
    "    label = inv_label_map[i]\n",
    "    cnf_matrix = confusion_matrix(y_test[:,i], p_valid[:,i]>0.2)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=[label], normalize=False,\n",
    "                      title=label)\n",
    "    total = cnf_matrix[0][0] + cnf_matrix[0][1] + cnf_matrix[1][0] + cnf_matrix[1][1]\n",
    "    actualYes = cnf_matrix[1][0] + cnf_matrix[1][1]\n",
    "    actualNo = cnf_matrix[0][0] + cnf_matrix[0][1]\n",
    "    predYes = cnf_matrix[0][1] + cnf_matrix[1][1]\n",
    "    plt.show()\n",
    "    print(\"Stats for \", label)\n",
    "    print(\"Accuracy (true positive + true negative) / total: \", (cnf_matrix[1][1] + cnf_matrix[0][0])/total)\n",
    "    print(\"FPR (when actually no, how often does it say yes): \", cnf_matrix[0][1]/actualNo)\n",
    "    print(\"TPR aka Recall (when actually yes, how often does it say yes): \", cnf_matrix[1][1]/actualYes)\n",
    "    print(\"Precision (when predicts yes, how often is it right): \", cnf_matrix[1][1]/predYes)\n",
    "    print(\"Prevalence (how often does actual yes occur in sample): \", actualYes/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
