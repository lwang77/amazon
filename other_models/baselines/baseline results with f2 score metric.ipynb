{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import scipy as scipy\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import dill\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "with open('tiffs.pkl', 'rb') as in_strm:\n",
    "    all_info = dill.load(in_strm)\n",
    "x_train = all_info[0]\n",
    "x_test = all_info[1]\n",
    "y_train = all_info[2]\n",
    "y_test = all_info[3]\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fbeta_score_keras(y_true, y_pred):\n",
    "    beta = 2\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "\n",
    "def fbeta_keras_online(y_true, y_pred, threshold_shift=-0.3):\n",
    "    beta = 2\n",
    "\n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = beta ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_crossentropy_with_fbeta(y_true, y_pred):\n",
    "    penalty_const = 0.0001\n",
    "    penalty = penalty_const * (1 - fbeta_keras_online(y_true, y_pred))\n",
    "    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1) + penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5479 samples\n",
      "Epoch 1/7\n",
      "35000/35000 [==============================] - 187s - loss: 0.6567 - acc: 0.3122 - val_loss: 0.2477 - val_acc: 0.5012\n",
      "Epoch 2/7\n",
      "35000/35000 [==============================] - 183s - loss: 0.2849 - acc: 0.3778 - val_loss: 0.2213 - val_acc: 0.5005\n",
      "Epoch 3/7\n",
      "35000/35000 [==============================] - 185s - loss: 0.2571 - acc: 0.3934 - val_loss: 0.2113 - val_acc: 0.5063\n",
      "Epoch 4/7\n",
      "35000/35000 [==============================] - 185s - loss: 0.2417 - acc: 0.4116 - val_loss: 0.2005 - val_acc: 0.5160\n",
      "Epoch 5/7\n",
      "35000/35000 [==============================] - 183s - loss: 0.2276 - acc: 0.4352 - val_loss: 0.2001 - val_acc: 0.5205\n",
      "Epoch 6/7\n",
      "35000/35000 [==============================] - 184s - loss: 0.2205 - acc: 0.4588 - val_loss: 0.1953 - val_acc: 0.5103\n",
      "Epoch 7/7\n",
      "35000/35000 [==============================] - 185s - loss: 0.2147 - acc: 0.4657 - val_loss: 0.1892 - val_acc: 0.5227\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[[ 0.06847271  0.01043847  0.29897368 ...,  0.02965965  0.14259568\n",
      "   0.02833995]\n",
      " [ 0.09815234  0.01568796  0.22894315 ...,  0.029207    0.28038764\n",
      "   0.0408434 ]\n",
      " [ 0.26550749  0.05561415  0.39012483 ...,  0.04651165  0.33103365\n",
      "   0.08838293]\n",
      " ..., \n",
      " [ 0.33051199  0.0067965   0.05479564 ...,  0.00839201  0.74840111\n",
      "   0.03780741]\n",
      " [ 0.29340854  0.01224715  0.11985572 ...,  0.01602243  0.676732\n",
      "   0.08945021]\n",
      " [ 0.13815248  0.00819488  0.12058246 ...,  0.00179451  0.1579328\n",
      "   0.01012986]]\n",
      "0.814052006067\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                input_shape=(32, 32, 4)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=binary_crossentropy_with_fbeta, \n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1000, epochs=7, verbose=1, \n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "p_valid = model.predict(x_test, batch_size=128)\n",
    "print(y_test)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_test, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5479 samples\n",
      "Epoch 1/7\n",
      "35000/35000 [==============================] - 184s - loss: 0.2140 - acc: 0.4757 - val_loss: 0.1904 - val_acc: 0.5267\n",
      "Epoch 2/7\n",
      "35000/35000 [==============================] - 186s - loss: 0.2185 - acc: 0.4861 - val_loss: 0.1983 - val_acc: 0.5136\n",
      "Epoch 3/7\n",
      "35000/35000 [==============================] - 183s - loss: 0.2123 - acc: 0.4924 - val_loss: 0.1909 - val_acc: 0.5200\n",
      "Epoch 4/7\n",
      "35000/35000 [==============================] - 181s - loss: 0.2045 - acc: 0.4978 - val_loss: 0.1814 - val_acc: 0.5187\n",
      "Epoch 5/7\n",
      "35000/35000 [==============================] - 183s - loss: 0.1991 - acc: 0.4975 - val_loss: 0.1818 - val_acc: 0.5154\n",
      "Epoch 6/7\n",
      "35000/35000 [==============================] - 182s - loss: 0.1935 - acc: 0.5007 - val_loss: 0.1738 - val_acc: 0.5297\n",
      "Epoch 7/7\n",
      "35000/35000 [==============================] - 188s - loss: 0.1890 - acc: 0.5048 - val_loss: 0.1757 - val_acc: 0.5306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11be28630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=1000, epochs=7, verbose=1, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[[ 0.10676392  0.00423981  0.57201827 ...,  0.0203518   0.19874991\n",
      "   0.01929451]\n",
      " [ 0.11797744  0.00628221  0.39176992 ...,  0.02416323  0.35258594\n",
      "   0.03501657]\n",
      " [ 0.24952155  0.05486738  0.60402089 ...,  0.03145219  0.3392486\n",
      "   0.05382715]\n",
      " ..., \n",
      " [ 0.36395019  0.02095278  0.08963784 ...,  0.00548943  0.66093034\n",
      "   0.09489788]\n",
      " [ 0.22619642  0.00615813  0.1436352  ...,  0.00339484  0.57740498\n",
      "   0.06620781]\n",
      " [ 0.04945116  0.00196876  0.1287621  ...,  0.00085437  0.09784374\n",
      "   0.0024065 ]]\n",
      "0.830370032078\n"
     ]
    }
   ],
   "source": [
    "p_valid = model.predict(x_test, batch_size=128)\n",
    "print(y_test)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_test, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5479 samples\n",
      "Epoch 1/4\n",
      "35000/35000 [==============================] - 190s - loss: 0.1840 - acc: 0.5051 - val_loss: 0.1670 - val_acc: 0.5267\n",
      "Epoch 2/4\n",
      "35000/35000 [==============================] - 189s - loss: 0.1810 - acc: 0.5078 - val_loss: 0.1661 - val_acc: 0.5317\n",
      "Epoch 3/4\n",
      "35000/35000 [==============================] - 184s - loss: 0.1799 - acc: 0.5093 - val_loss: 0.1658 - val_acc: 0.5306\n",
      "Epoch 4/4\n",
      "35000/35000 [==============================] - 184s - loss: 0.1785 - acc: 0.5103 - val_loss: 0.1648 - val_acc: 0.5315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1168b9ef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(loss=binary_crossentropy_with_fbeta, \n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1000, epochs=4, verbose=1, \n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[[ 0.12862794  0.00399382  0.61349905 ...,  0.01715657  0.19441065\n",
      "   0.01727507]\n",
      " [ 0.13428035  0.00783145  0.39315739 ...,  0.02850366  0.37531179\n",
      "   0.04404324]\n",
      " [ 0.35418913  0.13530651  0.61096793 ...,  0.03656367  0.35547483\n",
      "   0.08723994]\n",
      " ..., \n",
      " [ 0.41582555  0.00623724  0.05014039 ...,  0.00197364  0.8029018\n",
      "   0.06146602]\n",
      " [ 0.19326404  0.00182726  0.11283141 ...,  0.00122805  0.64084274\n",
      "   0.05530868]\n",
      " [ 0.07061765  0.00300248  0.15460153 ...,  0.00136772  0.16161974\n",
      "   0.00513008]]\n",
      "0.843678244271\n"
     ]
    }
   ],
   "source": [
    "p_valid = model.predict(x_test, batch_size=128)\n",
    "print(y_test)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_test, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5479 samples\n",
      "Epoch 1/4\n",
      "35000/35000 [==============================] - 190s - loss: 0.1786 - acc: 0.5108 - val_loss: 0.1641 - val_acc: 0.5320\n",
      "Epoch 2/4\n",
      "35000/35000 [==============================] - 185s - loss: 0.1768 - acc: 0.5131 - val_loss: 0.1631 - val_acc: 0.5284\n",
      "Epoch 3/4\n",
      "35000/35000 [==============================] - 192s - loss: 0.1759 - acc: 0.5141 - val_loss: 0.1629 - val_acc: 0.5286\n",
      "Epoch 4/4\n",
      "35000/35000 [==============================] - 204s - loss: 0.1748 - acc: 0.5131 - val_loss: 0.1624 - val_acc: 0.5309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11755e780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(loss=binary_crossentropy_with_fbeta, \n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1000, epochs=4, verbose=1, \n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[[ 0.14767465  0.00520725  0.61837405 ...,  0.01714492  0.21554402\n",
      "   0.01860865]\n",
      " [ 0.1472079   0.01019205  0.39849138 ...,  0.03245292  0.3943935\n",
      "   0.05383373]\n",
      " [ 0.3559061   0.19416258  0.62946814 ...,  0.03721603  0.3249661\n",
      "   0.10246442]\n",
      " ..., \n",
      " [ 0.45915231  0.00909899  0.06510434 ...,  0.00286657  0.80963182\n",
      "   0.08036362]\n",
      " [ 0.21001165  0.00250921  0.14867033 ...,  0.00166284  0.65772694\n",
      "   0.08177613]\n",
      " [ 0.05048526  0.00229371  0.11570133 ...,  0.00105798  0.14404659\n",
      "   0.00308428]]\n",
      "0.84797659228\n"
     ]
    }
   ],
   "source": [
    "p_valid = model.predict(x_test, batch_size=128)\n",
    "print(y_test)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_test, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5479 samples\n",
      "Epoch 1/4\n",
      "35000/35000 [==============================] - 198s - loss: 0.1737 - acc: 0.5143 - val_loss: 0.1621 - val_acc: 0.5286\n",
      "Epoch 2/4\n",
      "35000/35000 [==============================] - 188s - loss: 0.1734 - acc: 0.5155 - val_loss: 0.1620 - val_acc: 0.5291\n",
      "Epoch 3/4\n",
      "35000/35000 [==============================] - 199s - loss: 0.1735 - acc: 0.5137 - val_loss: 0.1618 - val_acc: 0.5289\n",
      "Epoch 4/4\n",
      "35000/35000 [==============================] - 209s - loss: 0.1733 - acc: 0.5143 - val_loss: 0.1619 - val_acc: 0.5275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fb56588>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.00001)\n",
    "model.compile(loss=binary_crossentropy_with_fbeta, \n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1000, epochs=4, verbose=1, \n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[[ 0.1506494   0.0052235   0.62543684 ...,  0.01591036  0.21541731\n",
      "   0.01841112]\n",
      " [ 0.15841334  0.01057222  0.39746171 ...,  0.03627377  0.39989465\n",
      "   0.05637174]\n",
      " [ 0.35107708  0.19688928  0.63052875 ...,  0.03302256  0.32733831\n",
      "   0.09991343]\n",
      " ..., \n",
      " [ 0.47336614  0.00793939  0.05724641 ...,  0.00244323  0.81640249\n",
      "   0.07375259]\n",
      " [ 0.217861    0.00186063  0.12753004 ...,  0.00137287  0.67238063\n",
      "   0.07092487]\n",
      " [ 0.0537655   0.00230758  0.11045907 ...,  0.001137    0.15405549\n",
      "   0.00335744]]\n",
      "0.848078829556\n"
     ]
    }
   ],
   "source": [
    "p_valid = model.predict(x_test, batch_size=128)\n",
    "print(y_test)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_test, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea for later....train with different losses??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
