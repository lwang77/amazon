{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run 2 is unet without normalization (3 depth) and normal dropout (following Lee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'conventional_mine': 0, 'water': 1, 'habitation': 2, 'blooming': 4, 'road': 5, 'clear': 16, 'haze': 6, 'bare_ground': 7, 'cultivation': 8, 'blow_down': 9, \n",
    " 'agriculture': 10, 'slash_burn': 12, 'primary': 11, 'artisinal_mine': 15, 'partly_cloudy': 13, 'cloudy': 14, 'selective_logging': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agriculture': 10,\n",
       " 'artisinal_mine': 15,\n",
       " 'bare_ground': 7,\n",
       " 'blooming': 4,\n",
       " 'blow_down': 9,\n",
       " 'clear': 16,\n",
       " 'cloudy': 14,\n",
       " 'conventional_mine': 0,\n",
       " 'cultivation': 8,\n",
       " 'habitation': 2,\n",
       " 'haze': 6,\n",
       " 'partly_cloudy': 13,\n",
       " 'primary': 11,\n",
       " 'road': 5,\n",
       " 'selective_logging': 3,\n",
       " 'slash_burn': 12,\n",
       " 'water': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train on 35000 samples, validate on 5479 samples\n",
    "Epoch 1/20\n",
    "2017-06-17 08:14:41.536619: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:14:41.536656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:14:41.536665: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:14:41.536672: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:14:41.536681: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.2046 - acc: 0.9172 Epoch 00000: val_loss improved from inf to 0.17720, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 4101s - loss: 0.2045 - acc: 0.9172 - val_loss: 0.1772 - val_acc: 0.9291\n",
    "Epoch 2/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.1606 - acc: 0.9353 Epoch 00001: val_loss improved from 0.17720 to 0.16012, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 4134s - loss: 0.1605 - acc: 0.9353 - val_loss: 0.1601 - val_acc: 0.9352\n",
    "Epoch 3/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.1438 - acc: 0.9423 Epoch 00002: val_loss improved from 0.16012 to 0.14296, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 4137s - loss: 0.1438 - acc: 0.9423 - val_loss: 0.1430 - val_acc: 0.9432\n",
    "Epoch 4/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.1343 - acc: 0.9461 Epoch 00003: val_loss improved from 0.14296 to 0.13965, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 4115s - loss: 0.1342 - acc: 0.9461 - val_loss: 0.1397 - val_acc: 0.9441\n",
    "Epoch 5/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.1267 - acc: 0.9490 Epoch 00004: val_loss improved from 0.13965 to 0.13663, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 4132s - loss: 0.1267 - acc: 0.9490 - val_loss: 0.1366 - val_acc: 0.9444\n",
    "Epoch 6/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.1200 - acc: 0.9517 Epoch 00005: val_loss improved from 0.13663 to 0.12980, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 4124s - loss: 0.1200 - acc: 0.9517 - val_loss: 0.1298 - val_acc: 0.9473\n",
    "Epoch 7/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.1132 - acc: 0.9543 Epoch 00006: val_loss did not improve\n",
    "35000/35000 [==============================] - 4131s - loss: 0.1132 - acc: 0.9543 - val_loss: 0.1303 - val_acc: 0.9480\n",
    "Epoch 8/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.1032 - acc: 0.9587 Epoch 00007: val_loss did not improve\n",
    "35000/35000 [==============================] - 4071s - loss: 0.1032 - acc: 0.9586 - val_loss: 0.1338 - val_acc: 0.9478\n",
    "Epoch 9/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0920 - acc: 0.9629 Epoch 00008: val_loss did not improve\n",
    "35000/35000 [==============================] - 4032s - loss: 0.0920 - acc: 0.9629 - val_loss: 0.1443 - val_acc: 0.9443\n",
    "Epoch 10/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0796 - acc: 0.9682 Epoch 00009: val_loss did not improve\n",
    "35000/35000 [==============================] - 4146s - loss: 0.0795 - acc: 0.9682 - val_loss: 0.1640 - val_acc: 0.9452\n",
    "Epoch 11/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0657 - acc: 0.9739 Epoch 00010: val_loss did not improve\n",
    "35000/35000 [==============================] - 4133s - loss: 0.0657 - acc: 0.9739 - val_loss: 0.1752 - val_acc: 0.9458\n",
    "Epoch 12/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0510 - acc: 0.9803 Epoch 00011: val_loss did not improve\n",
    "35000/35000 [==============================] - 4139s - loss: 0.0510 - acc: 0.9803 - val_loss: 0.2046 - val_acc: 0.9438\n",
    "Epoch 13/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0404 - acc: 0.9844 Epoch 00012: val_loss did not improve\n",
    "35000/35000 [==============================] - 4153s - loss: 0.0404 - acc: 0.9844 - val_loss: 0.2459 - val_acc: 0.9445\n",
    "Epoch 14/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0328 - acc: 0.9874 Epoch 00013: val_loss did not improve\n",
    "35000/35000 [==============================] - 4147s - loss: 0.0328 - acc: 0.9874 - val_loss: 0.2683 - val_acc: 0.9389\n",
    "Epoch 15/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0272 - acc: 0.9896 Epoch 00014: val_loss did not improve\n",
    "35000/35000 [==============================] - 4140s - loss: 0.0273 - acc: 0.9895 - val_loss: 0.2939 - val_acc: 0.9434\n",
    "Epoch 16/20\n",
    "34944/35000 [============================>.] - ETA: 6s - loss: 0.0268 - acc: 0.9902 Epoch 00015: val_loss did not improve\n",
    "35000/35000 [==============================] - 4121s - loss: 0.0269 - acc: 0.9902 - val_loss: 0.2972 - val_acc: 0.9425\n",
    "Epoch 17/20\n",
    "16896/35000 [=============>................] - ETA: 2018s - loss: 0.0166 - acc: 0.994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max accuracy 0.9478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observations: unet is overfitting a lot. more dropout layers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
