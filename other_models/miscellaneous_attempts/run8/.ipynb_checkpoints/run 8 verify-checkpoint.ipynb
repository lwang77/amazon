{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import scipy as scipy\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import dill\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "import math\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = {'agriculture': 4, 'selective_logging': 0, 'primary': 1, 'blow_down': 10, 'cloudy': 3, 'slash_burn': 2, 'artisinal_mine': 5, 'clear': 6, 'cultivation': 7, 'conventional_mine': 8, 'habitation': 9, 'road': 11, 'haze': 12, 'blooming': 14, 'water': 15, 'partly_cloudy': 16, 'bare_ground': 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "\n",
    "for i in range(40669):\n",
    "    img = cv2.imread('../../DB/test-jpg/test_{}.jpg'.format(i))\n",
    "    x_test.append(cv2.resize(img, (72, 72)))\n",
    "    \n",
    "    \n",
    "for i in range(20522):\n",
    "    img = cv2.imread('../../DB/test-jpg-additional/file_{}.jpg'.format(i))\n",
    "    x_test.append(cv2.resize(img, (72, 72)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array(x_test, np.float16) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 72, 72, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 72, 72, 3)     12          input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 72, 72, 32)    896         batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 72, 72, 32)    9248        conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 36, 36, 32)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 36, 36, 32)    0           max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 36, 36, 32)    128         dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 36, 36, 64)    18496       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 36, 36, 64)    36928       conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 18, 18, 64)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 18, 18, 64)    0           max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 18, 18, 64)    256         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 18, 18, 128)   73856       batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 18, 18, 128)   147584      conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 9, 9, 128)     0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 9, 9, 128)     0           max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 9, 9, 128)     512         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 9, 9, 256)     295168      batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 9, 9, 256)     590080      conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 64)            0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (None, 128)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glob (None, 256)           0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 448)           0           global_average_pooling2d_1[0][0] \n",
      "                                                                   global_average_pooling2d_2[0][0] \n",
      "                                                                   global_average_pooling2d_3[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           229888      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 17)            8721        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,411,773\n",
      "Trainable params: 1,411,319\n",
      "Non-trainable params: 454\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(72, 72, 3))\n",
    "batch1 = BatchNormalization()(input_layer)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(batch1)\n",
    "conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "max1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "drop1 = Dropout(0.3)(max1)\n",
    "\n",
    "batch2 = BatchNormalization()(drop1)\n",
    "conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(batch2)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
    "max2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "drop2 = Dropout(0.3)(max2)\n",
    "\n",
    "batch3 = BatchNormalization()(drop2)\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(batch3)\n",
    "conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "max3 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "drop3 = Dropout(0.3)(max3)\n",
    "\n",
    "batch4 = BatchNormalization()(drop3)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(batch4)\n",
    "conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "globAv1 = GlobalAveragePooling2D()(drop2)\n",
    "globAv2 = GlobalAveragePooling2D()(drop3)\n",
    "globAv3 = GlobalAveragePooling2D()(conv8)\n",
    "\n",
    "conc = concatenate([globAv1, globAv2, globAv3])\n",
    "\n",
    "dense1 = Dense(512, activation='relu')(conc)\n",
    "drop4 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(17, activation='sigmoid')(drop4)\n",
    "unet = Model(inputs=[input_layer], outputs=dense2)\n",
    "\n",
    "unet.summary()\n",
    "\n",
    "unet.load_weights('run8_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = unet.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_predictions(predictions, labels_map, thresholds):\n",
    "    \"\"\"\n",
    "    Return the predictions mapped to their labels\n",
    "    :param predictions: the predictions from the predict() method\n",
    "    :param labels_map: the map\n",
    "    :param thresholds: The threshold of each class to be considered as existing or not existing\n",
    "    :return: the predictions list mapped to their labels\n",
    "    \"\"\"\n",
    "    predictions_labels = []\n",
    "    for prediction in predictions:\n",
    "        labels = [labels_map[i] for i, value in enumerate(prediction) if value > thresholds[i]]\n",
    "        predictions_labels.append(labels)\n",
    "\n",
    "    return predictions_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191,)\n"
     ]
    }
   ],
   "source": [
    "inv_label_map = {value: key for key, value in label_map.items()}\n",
    "thres = [0.2] * len(label_map)\n",
    "predicted_labels = map_predictions(predictions, inv_label_map, thres)\n",
    "\n",
    "x_test_filename = ['test_{}.jpg'.format(i) for i in range(40669)]\n",
    "x_test_filename2 = ['file_{}.jpg'.format(i) for i in range(20522)]\n",
    "x_test_filename = np.hstack((x_test_filename, x_test_filename2))\n",
    "print(x_test_filename.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_list = [None] * len(predicted_labels)\n",
    "for i, tags in enumerate(predicted_labels):\n",
    "    tags_list[i] = ' '.join(map(str, tags))\n",
    "\n",
    "final_data = [[filename.split(\".\")[0], tags] for filename, tags in zip(x_test_filename, tags_list)]\n",
    "\n",
    "final_df = pd.DataFrame(final_data, columns=['image_name', 'tags'])\n",
    "final_df.head()\n",
    "\n",
    "final_df.to_csv('run8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "got 0.92090^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below: optimizing thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
    "  def mf(x):\n",
    "    p2 = np.zeros_like(p)\n",
    "    for i in range(17):\n",
    "      p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
    "    score = fbeta_score(y, p2, beta=2, average='samples')\n",
    "    return score\n",
    "\n",
    "  x = [0.2]*17\n",
    "  for i in range(17):\n",
    "    best_i2 = 0\n",
    "    best_score = 0\n",
    "    for i2 in range(resolution):\n",
    "      i2 /= resolution\n",
    "      x[i] = i2\n",
    "      score = mf(x)\n",
    "      if score > best_score:\n",
    "        best_i2 = i2\n",
    "        best_score = score\n",
    "    x[i] = best_i2\n",
    "    if verbose:\n",
    "      print(i, best_i2, best_score)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [11:48<00:00, 57.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 72, 72, 3)\n",
      "(40479, 17)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('../../DB/train_v2.csv')\n",
    "\n",
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread('../../DB/train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (72, 72)))\n",
    "    y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float16) / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "split = 35000\n",
    "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.12 0.921845831959\n",
      "1 0.23 0.921983458979\n",
      "2 0.18 0.92202039655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.09 0.922995252029\n",
      "4 0.17 0.923018840605\n",
      "5 0.1 0.923021273002\n",
      "6 0.19 0.923099722974\n",
      "7 0.26 0.923279553869\n",
      "8 0.3 0.92330304242\n",
      "9 0.18 0.923423868258\n",
      "10 0.21 0.923432815075\n",
      "11 0.21 0.923498359135\n",
      "12 0.23 0.923591710599\n",
      "13 0.19 0.923702622196\n",
      "14 0.23 0.923756349572\n",
      "15 0.2 0.923756349572\n",
      "16 0.26 0.923865217908\n"
     ]
    }
   ],
   "source": [
    "x_valid_pred = unet.predict(x_valid)\n",
    "opt_thresh = optimise_f2_thresholds(y_valid, x_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_new_thresh = []\n",
    "\n",
    "for prediction in predictions:\n",
    "    labels = [inv_label_map[i] for i, value in enumerate(prediction) if value > opt_thresh[i]]\n",
    "    predicted_labels_new_thresh.append(labels)\n",
    "\n",
    "    \n",
    "tags_list = [None] * len(predicted_labels_new_thresh)\n",
    "for i, tags in enumerate(predicted_labels_new_thresh):\n",
    "    tags_list[i] = ' '.join(map(str, tags))\n",
    "\n",
    "final_data = [[filename.split(\".\")[0], tags] for filename, tags in zip(x_test_filename, tags_list)]\n",
    "\n",
    "final_df = pd.DataFrame(final_data, columns=['image_name', 'tags'])\n",
    "final_df.head()\n",
    "\n",
    "final_df.to_csv('run8_opt_thresh.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ got 0.92053 for some reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to run f-score with 0.2 thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921802446485\n"
     ]
    }
   ],
   "source": [
    "print(fbeta_score(y_valid, np.array(x_valid_pred) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying optimized thresholds with lower resolution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2 0.921802446485\n",
      "1 0.2 0.921802446485\n",
      "2 0.3 0.92182989404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.1 0.922772552599\n",
      "4 0.2 0.922772552599\n",
      "5 0.1 0.922774184491\n",
      "6 0.2 0.922774184491\n",
      "7 0.2 0.922774184491\n",
      "8 0.3 0.922795838438\n",
      "9 0.3 0.922858352835\n",
      "10 0.2 0.922858352835\n",
      "11 0.2 0.922858352835\n",
      "12 0.2 0.922858352835\n",
      "13 0.1 0.922884819517\n",
      "14 0.3 0.922916777326\n",
      "15 0.2 0.922916777326\n",
      "16 0.2 0.922916777326\n"
     ]
    }
   ],
   "source": [
    "opt_thresh2 = optimise_f2_thresholds(y_valid, x_valid_pred, resolution=10)\n",
    "predicted_labels_new_thresh = []\n",
    "\n",
    "for prediction in predictions:\n",
    "    labels = [inv_label_map[i] for i, value in enumerate(prediction) if value > opt_thresh2[i]]\n",
    "    predicted_labels_new_thresh.append(labels)\n",
    "\n",
    "    \n",
    "tags_list = [None] * len(predicted_labels_new_thresh)\n",
    "for i, tags in enumerate(predicted_labels_new_thresh):\n",
    "    tags_list[i] = ' '.join(map(str, tags))\n",
    "\n",
    "final_data = [[filename.split(\".\")[0], tags] for filename, tags in zip(x_test_filename, tags_list)]\n",
    "\n",
    "final_df = pd.DataFrame(final_data, columns=['image_name', 'tags'])\n",
    "final_df.head()\n",
    "\n",
    "final_df.to_csv('run8_opt_thresh2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "got 0.92050^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
