{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(run 1) instance 1 is herkeng with batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = {'road': 0, 'cultivation': 4, 'blow_down': 3, \n",
    "             'slash_burn': 2, 'conventional_mine': 1, 'habitation': 9, \n",
    "             'partly_cloudy': 5, 'selective_logging': 7, 'bare_ground': 6, \n",
    "             'haze': 8, 'clear': 10, 'artisinal_mine': 12, 'cloudy': 11, \n",
    "             'primary': 14, 'water': 15, 'blooming': 16, 'agriculture': 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agriculture': 13,\n",
       " 'artisinal_mine': 12,\n",
       " 'bare_ground': 6,\n",
       " 'blooming': 16,\n",
       " 'blow_down': 3,\n",
       " 'clear': 10,\n",
       " 'cloudy': 11,\n",
       " 'conventional_mine': 1,\n",
       " 'cultivation': 4,\n",
       " 'habitation': 9,\n",
       " 'haze': 8,\n",
       " 'partly_cloudy': 5,\n",
       " 'primary': 14,\n",
       " 'road': 0,\n",
       " 'selective_logging': 7,\n",
       " 'slash_burn': 2,\n",
       " 'water': 15}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train on 35000 samples, validate on 5479 samples\n",
    "Epoch 1/20\n",
    "2017-06-17 08:04:38.262286: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:04:38.262330: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:04:38.262338: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:04:38.262345: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2017-06-17 08:04:38.262357: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.1700 - acc: 0.9323Epoch 00000: val_loss improved from inf to 0.28845, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 1174s - loss: 0.1700 - acc: 0.9323 - val_loss: 0.2884 - val_acc: 0.9092\n",
    "Epoch 2/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.1310 - acc: 0.9482Epoch 00001: val_loss improved from 0.28845 to 0.13147, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 1176s - loss: 0.1310 - acc: 0.9482 - val_loss: 0.1315 - val_acc: 0.9473\n",
    "Epoch 3/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.1187 - acc: 0.9531Epoch 00002: val_loss improved from 0.13147 to 0.12419, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 1179s - loss: 0.1187 - acc: 0.9531 - val_loss: 0.1242 - val_acc: 0.9518\n",
    "Epoch 4/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.1105 - acc: 0.9567Epoch 00003: val_loss improved from 0.12419 to 0.11129, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 1176s - loss: 0.1104 - acc: 0.9567 - val_loss: 0.1113 - val_acc: 0.9559\n",
    "Epoch 5/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.1055 - acc: 0.9585Epoch 00004: val_loss did not improve\n",
    "35000/35000 [==============================] - 1179s - loss: 0.1055 - acc: 0.9585 - val_loss: 0.1175 - val_acc: 0.9542\n",
    "Epoch 6/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.1021 - acc: 0.9597Epoch 00005: val_loss did not improve\n",
    "35000/35000 [==============================] - 1180s - loss: 0.1021 - acc: 0.9598 - val_loss: 0.1116 - val_acc: 0.9557\n",
    "Epoch 7/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0986 - acc: 0.9613Epoch 00006: val_loss did not improve\n",
    "35000/35000 [==============================] - 1172s - loss: 0.0986 - acc: 0.9613 - val_loss: 0.1185 - val_acc: 0.9531\n",
    "Epoch 8/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0962 - acc: 0.9621Epoch 00007: val_loss improved from 0.11129 to 0.10777, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 1163s - loss: 0.0962 - acc: 0.9621 - val_loss: 0.1078 - val_acc: 0.9587\n",
    "Epoch 9/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0931 - acc: 0.9635Epoch 00008: val_loss did not improve\n",
    "35000/35000 [==============================] - 1168s - loss: 0.0931 - acc: 0.9635 - val_loss: 0.1176 - val_acc: 0.9536\n",
    "Epoch 10/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0907 - acc: 0.9646Epoch 00009: val_loss did not improve\n",
    "35000/35000 [==============================] - 1171s - loss: 0.0907 - acc: 0.9645 - val_loss: 0.1121 - val_acc: 0.9564\n",
    "Epoch 11/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0886 - acc: 0.9653Epoch 00010: val_loss improved from 0.10777 to 0.10195, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 1166s - loss: 0.0886 - acc: 0.9653 - val_loss: 0.1020 - val_acc: 0.9617\n",
    "Epoch 12/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0860 - acc: 0.9665Epoch 00011: val_loss did not improve\n",
    "35000/35000 [==============================] - 1160s - loss: 0.0860 - acc: 0.9665 - val_loss: 0.1035 - val_acc: 0.9597\n",
    "Epoch 13/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0851 - acc: 0.9667Epoch 00012: val_loss improved from 0.10195 to 0.10088, saving model to weights.hdf5\n",
    "35000/35000 [==============================] - 1172s - loss: 0.0851 - acc: 0.9667 - val_loss: 0.1009 - val_acc: 0.9616\n",
    "Epoch 14/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0811 - acc: 0.9684Epoch 00013: val_loss did not improve\n",
    "35000/35000 [==============================] - 1183s - loss: 0.0811 - acc: 0.9684 - val_loss: 0.1043 - val_acc: 0.9595\n",
    "Epoch 15/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0795 - acc: 0.9691Epoch 00014: val_loss did not improve\n",
    "35000/35000 [==============================] - 1175s - loss: 0.0795 - acc: 0.9691 - val_loss: 0.1012 - val_acc: 0.9621\n",
    "Epoch 16/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0758 - acc: 0.9703Epoch 00015: val_loss did not improve\n",
    "35000/35000 [==============================] - 1179s - loss: 0.0758 - acc: 0.9703 - val_loss: 0.1071 - val_acc: 0.9610\n",
    "Epoch 17/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0716 - acc: 0.9719Epoch 00016: val_loss did not improve\n",
    "35000/35000 [==============================] - 1176s - loss: 0.0715 - acc: 0.9719 - val_loss: 0.1031 - val_acc: 0.9606\n",
    "Epoch 18/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0699 - acc: 0.9728Epoch 00017: val_loss did not improve\n",
    "35000/35000 [==============================] - 1178s - loss: 0.0699 - acc: 0.9728 - val_loss: 0.1065 - val_acc: 0.9612\n",
    "Epoch 19/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0667 - acc: 0.9739Epoch 00018: val_loss did not improve\n",
    "35000/35000 [==============================] - 1176s - loss: 0.0668 - acc: 0.9739 - val_loss: 0.1129 - val_acc: 0.9602\n",
    "Epoch 20/20\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0645 - acc: 0.9747Epoch 00019: val_loss did not improve\n",
    "35000/35000 [==============================] - 1172s - loss: 0.0645 - acc: 0.9747 - val_loss: 0.1402 - val_acc: 0.9512\n",
    "Train on 35000 samples, validate on 5479 samples\n",
    "Epoch 1/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0508 - acc: 0.9804Epoch 00000: val_loss did not improve\n",
    "35000/35000 [==============================] - 1184s - loss: 0.0508 - acc: 0.9804 - val_loss: 0.1111 - val_acc: 0.9617\n",
    "Epoch 2/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0454 - acc: 0.9827Epoch 00001: val_loss did not improve\n",
    "35000/35000 [==============================] - 1175s - loss: 0.0454 - acc: 0.9827 - val_loss: 0.1163 - val_acc: 0.9616\n",
    "Epoch 3/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0429 - acc: 0.9837Epoch 00002: val_loss did not improve\n",
    "35000/35000 [==============================] - 1177s - loss: 0.0429 - acc: 0.9837 - val_loss: 0.1213 - val_acc: 0.9610\n",
    "Epoch 4/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0407 - acc: 0.9847Epoch 00003: val_loss did not improve\n",
    "35000/35000 [==============================] - 1179s - loss: 0.0408 - acc: 0.9847 - val_loss: 0.1260 - val_acc: 0.9611\n",
    "Epoch 5/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0387 - acc: 0.9855Epoch 00004: val_loss did not improve\n",
    "35000/35000 [==============================] - 1168s - loss: 0.0387 - acc: 0.9855 - val_loss: 0.1308 - val_acc: 0.9608\n",
    "Train on 35000 samples, validate on 5479 samples\n",
    "Epoch 1/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0361 - acc: 0.9865Epoch 00000: val_loss did not improve\n",
    "35000/35000 [==============================] - 1168s - loss: 0.0361 - acc: 0.9865 - val_loss: 0.1311 - val_acc: 0.9607\n",
    "Epoch 2/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0356 - acc: 0.9868Epoch 00001: val_loss did not improve\n",
    "35000/35000 [==============================] - 1170s - loss: 0.0356 - acc: 0.9868 - val_loss: 0.1319 - val_acc: 0.9607\n",
    "Epoch 3/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0354 - acc: 0.9869Epoch 00002: val_loss did not improve\n",
    "35000/35000 [==============================] - 1169s - loss: 0.0354 - acc: 0.9869 - val_loss: 0.1327 - val_acc: 0.9607\n",
    "Epoch 4/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0351 - acc: 0.9870Epoch 00003: val_loss did not improve\n",
    "35000/35000 [==============================] - 1168s - loss: 0.0351 - acc: 0.9870 - val_loss: 0.1340 - val_acc: 0.9609\n",
    "Epoch 5/5\n",
    "34944/35000 [============================>.] - ETA: 1s - loss: 0.0349 - acc: 0.9873Epoch 00004: val_loss did not improve\n",
    "35000/35000 [==============================] - 1165s - loss: 0.0349 - acc: 0.9873 - val_loss: 0.1341 - val_acc: 0.9607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max accuracy 0.9621"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observations: HerKeng Cheng model is overfitting a looot. Between this and the other Herkeng Cheng runs (runs 6 and 7) there is no statistical improvement from making it deeper or wider. So, we will try all three again with dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
